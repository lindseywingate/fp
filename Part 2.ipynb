{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import skimage\n",
    "from skimage.metrics import structural_similarity\n",
    "from skimage import data, draw, io\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reads in video to init_video\n",
    "with open(\"dataset/Videos/test2.rgb\", \"rb\") as f:\n",
    "    v = np.fromfile(f, np.dtype('B'))\n",
    "#setting the number of pixels in frame\n",
    "pxct = 129600\n",
    "#setting the number of frames\n",
    "frct = (int)(v.size/(3*pxct))\n",
    "init_video = []\n",
    "for frame_number in range(frct):\n",
    "        start = (frame_number) * pxct * 3\n",
    "        curr_frame = v[start:start + 3 * pxct]\n",
    "        final_frame = np.reshape(curr_frame, (480,270,3), order = 'F')\n",
    "        final_frame = np.rot90(final_frame,3)\n",
    "        final_frame = np.flip(final_frame,1)\n",
    "        \n",
    "        #searching these final frames for logos (new cell)\n",
    "        init_video.append(final_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate cuts for advertisement\n",
    "advert_frames = []\n",
    "for frame_number in range(frct - 1):\n",
    "    #calculate new shots with histogram\n",
    "    #less means more similar\n",
    "    hist1 = cv2.calcHist([init_video[frame_number]],[0],None,[256],[0,256])\n",
    "    hist2 = cv2.calcHist([init_video[frame_number + 1]],[0],None,[256],[0,256])\n",
    "    score=cv2.compareHist(hist1,hist2,cv2.HISTCMP_BHATTACHARYYA)\n",
    "    #store score for ssi\n",
    "    #less means more similar\n",
    "    #i1 = cv2.cvtColor(init_video[frame_number], cv2.COLOR_BGR2GRAY)\n",
    "    #i2 = cv2.cvtColor(init_video[frame_number + 1], cv2.COLOR_BGR2GRAY)\n",
    "    #score2 = structural_similarity(i1, i2)\n",
    "    #score2 = 1-score2 \n",
    "    #frame_stats[frame_number][1] = score2\n",
    "    \n",
    "    #score indicates sensitivity for shot changes\n",
    "    if score > 0.2:\n",
    "        advert_frames.append(frame_number)\n",
    "        advert_frames.append(frame_number+1)\n",
    "        #saves the image, currently used for debugging\n",
    "        #if score + score2 > 0.3:\n",
    "        data = Image.fromarray(init_video[frame_number]).convert('RGB')\n",
    "        data.save('images_cut/{}.png'.format(frame_number))\n",
    "        data = Image.fromarray(init_video[frame_number+1]).convert('RGB')\n",
    "        data.save('images_cut/{}.png'.format(frame_number+1))\n",
    "#save beginning and end of cuts in number of frames\n",
    "#storing the advertisements to replace with\n",
    "#indexed the same way as that of cuts_begin and cuts_end\n",
    "#if not to be replaced, a blank line\n",
    "replaced_advertisements = []\n",
    "cuts_begin = []\n",
    "cuts_end = []\n",
    "for i in range(len(advert_frames)):\n",
    "    for j in range(i,len(advert_frames)):\n",
    "        if advert_frames[j] - advert_frames[i] == 449:\n",
    "            cuts_begin.append(advert_frames[i])\n",
    "            cuts_end.append(advert_frames[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuts_begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cuts_begin has all starts of clips of 15seconds (449 frames) long exactly\n",
    "#cuts_end has all the ends\n",
    "print(advert_frames)\n",
    "cuts_begin = []\n",
    "cuts_end = []\n",
    "for i in range(len(advert_frames)):\n",
    "    for j in range(i,len(advert_frames)):\n",
    "        if advert_frames[j] - advert_frames[i] == 449:\n",
    "            cuts_begin.append(advert_frames[i])\n",
    "            cuts_end.append(advert_frames[j])\n",
    "print(cuts_begin)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in all other advertisements\n",
    "#saves in a dictionary with first part assumed to be the company name\n",
    "\n",
    "advertisements = {}\n",
    "PATHS_TO_ADVERTISEMENTS = \"dataset/Ads\"\n",
    "for file in os.listdir(PATHS_TO_ADVERTISEMENTS):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.endswith(\".rgb\"): \n",
    "        vpath = os.path.join(PATHS_TO_ADVERTISEMENTS, filename)\n",
    "        with open(vpath, \"rb\") as f:\n",
    "            v = np.fromfile(f, np.dtype('B'))\n",
    "        #setting the number of pixels in frame\n",
    "        pxct = 129600\n",
    "        #setting the number of frames\n",
    "        frct = (int)(v.size/(3*pxct))\n",
    "        video = []\n",
    "        for frame_number in range(frct):\n",
    "            start = (frame_number) * pxct * 3\n",
    "            curr_frame = v[start:start + 3 * pxct]\n",
    "            final_frame = np.reshape(curr_frame, ( 480,270, 3), order = 'F')\n",
    "            final_frame = np.rot90(final_frame,3)\n",
    "            final_frame = np.flip(final_frame,1)\n",
    "            video.append(final_frame)\n",
    "        #Get the name of the company\n",
    "        key = filename.split('_')[0]\n",
    "        advertisements[key] = video\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splicing in videos with the names \n",
    "#save beginning and end of cuts in number of frames\n",
    "cuts_begin = [2585,7006]\n",
    "cuts_end = [3034, 7455]\n",
    "#storing the advertisements to replace with\n",
    "#indexed the same way as that of cuts_begin and cuts_end\n",
    "#if not to be replaced, an empty string\n",
    "replaced_advertisements = [\"Starbucks\", \"Subway\"]\n",
    "final_video = []\n",
    "for i in range (len(cuts_begin)):\n",
    "    if i == 0:\n",
    "        final_video = init_video[:cuts_begin[i]] + advertisements[replaced_advertisements[i]] + init_video[cuts_end[i]:]\n",
    "    else:\n",
    "        #further work required to sync frames iff replacement ad lengths are variable\n",
    "        final_video = final_video[:cuts_begin[i]] + advertisements[replaced_advertisements[i]] + final_video[cuts_end[i]:]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = init_video[1388]\n",
    "data = Image.fromarray(t).convert('RGB')\n",
    "data.save('box-test.png'.format(1))\n",
    "img = cv2.imread('box-test.png')\n",
    "y = np.flip(t,axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0th index of returned list is boolean\n",
    "# 1st index is stuff needed to draw\n",
    "def full_logo_recognition(frame, logo):\n",
    "    #read in logo \n",
    "    graylogo = cv2.cvtColor(logo, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# #change to grayscale\n",
    "    grayframe = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #sift = cv2.SIFT_create()\n",
    "    #logopoints, logodescriptors = sift.detectAndCompute(graylogo, None)\n",
    "    #framepoints, framedescriptors = sift.detectAndCompute(grayframe, None)\n",
    "    #print(logopoints)\n",
    "    #bf = cv2.BFMatcher(cv2.NORM_L1, crossCheck=True)\n",
    "    #bf = cv2.BFMatcher()\n",
    "\n",
    "    sift = cv2.ORB_create(nfeatures=1500,edgeThreshold = 16, patchSize=16)\n",
    "    logopoints, logodescriptors = sift.detectAndCompute(graylogo, None)\n",
    "    framepoints, framedescriptors = sift.detectAndCompute(grayframe, None)\n",
    "    \n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "    \n",
    "    matches = bf.knnMatch(logodescriptors,framedescriptors, k=2)\n",
    "\n",
    "    # Apply ratio test\n",
    "    good_points = []\n",
    "    good_points_nolist = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.8*n.distance:\n",
    "            good_points.append([m])\n",
    "            good_points_nolist.append(m)\n",
    "    #print(good_points)\n",
    "\n",
    "#cv2.drawMatchesKnn expects list of lists as matches.\n",
    "    img3 = cv2.drawMatchesKnn(logo, logopoints, frame, framepoints, good_points, None,\n",
    "                              matchColor=(0, 255, 0), matchesMask=None,\n",
    "                              singlePointColor=(255, 0, 0), flags=0)\n",
    "    returnlist = [good_points_nolist, logopoints, framepoints]\n",
    "    return ([len(good_points) >= 0.08*len(logodescriptors), returnlist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_frames(frame, good_points_nolist, logopoints, framepoints, logodims, logoresize, color):\n",
    "    list_kp1 = []\n",
    "    list_framepoints = []\n",
    "    for mat in good_points_nolist:\n",
    "\n",
    "    # Get the matching keypoints for each of the images\n",
    "        img1_idx = mat.queryIdx\n",
    "        img2_idx = mat.trainIdx\n",
    "\n",
    "    # x - columns\n",
    "    # y - rows\n",
    "    # Get the coordinates\n",
    "        (x1, y1) = logopoints[img1_idx].pt\n",
    "        (x2, y2) = framepoints[img2_idx].pt\n",
    "\n",
    "    # Append to each list\n",
    "        #list_kp1.append((x1, y1))\n",
    "        list_framepoints.append((x2, y2))\n",
    "        img = np.ascontiguousarray(frame, dtype=np.uint8)\n",
    "        #get new saved png frame\n",
    "\n",
    "    if(len(list_framepoints) > 0):\n",
    "        average = len(list_framepoints);\n",
    "        x=0\n",
    "        y=0\n",
    "        x_tempmin=0\n",
    "        y_tempmin=0\n",
    "        for pt in list_framepoints: \n",
    "            x_tempmin = min([x_tempmin,pt[0]])\n",
    "            y_tempmin = min([y_tempmin,pt[1]])\n",
    "            x = x+pt[0]\n",
    "            y = y+pt[1] \n",
    "        x_average = int(x/average)\n",
    "        y_average = int(y/average)\n",
    "\n",
    "        center_coordinates = (x_average, y_average)\n",
    "        radius = 5\n",
    "        \n",
    "        thickness = 4\n",
    "        #image = cv2.circle(img, center_coordinates, radius, color, thickness)\n",
    "        logoresizex = ((x_tempmin - x_average)/logodims[0] + 0.3)/2\n",
    "        logoresizey = ((y_tempmin - y_average)/logodims[1] + 0.3)/2\n",
    "        #logoresizey = logoresize\n",
    "        #logoresizex = logoresize\n",
    "        xlsz = int(logodims[0] * logoresizex)\n",
    "        ylsz = int(logodims[1] * logoresizey) \n",
    "        xmin = max([x_average - xlsz,1])\n",
    "        ymin = max([y_average - ylsz,1])\n",
    "        xmax = min([x_average + xlsz,479])\n",
    "        ymax = min([y_average + ylsz,269])\n",
    "        image = cv2.rectangle(img, (int(xmin),int(ymin)), (int(xmax),int(ymax)), color, thickness)\n",
    "        return np.flip(image, axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final\n",
    "scale = cv2.imread('Dataset/Brand Images/{company}_logo.bmp'.format(company = \"starbucks\"))\n",
    "scale_percent = 30 # percent of original size\n",
    "width = int(scale.shape[1] * scale_percent / 100)\n",
    "height = int(scale.shape[0] * scale_percent / 100)\n",
    "dim = (width, height)\n",
    "resized = cv2.resize(scale, dim, interpolation = cv2.INTER_AREA)\n",
    "st = resized\n",
    "sw = cv2.imread('Dataset/Brand Images/{company}_logo.bmp'.format(company = \"subway\"))\n",
    "for k in range(0,1860):\n",
    "    try:\n",
    "        frame = init_video[k]\n",
    "        stretarr = full_logo_recognition(frame, st)\n",
    "        swretarr = full_logo_recognition(frame, sw)\n",
    "        if stretarr[0]:\n",
    "            init_video[k] = draw_frames(frame,stretarr[1][0],stretarr[1][1],stretarr[1][2], [480,130], 0.3, (0, 255, 0))\n",
    "        if swretarr[0]:\n",
    "            init_video[k] = draw_frames(frame,swretarr[1][0],swretarr[1][1],swretarr[1][2], [480,130], 0.3, ( 255,0, 0))\n",
    "    except:\n",
    "        print (k)\n",
    "for k in range(1860,2550):\n",
    "    try:\n",
    "        frame = init_video[k]\n",
    "        stretarr = full_logo_recognition(frame, st)\n",
    "        if stretarr[0]:\n",
    "            init_video[k] = draw_frames(frame,stretarr[1][0],stretarr[1][1],stretarr[1][2], [480,130], 0.3, ( 255,0, 0))\n",
    "    except:\n",
    "        print (k)\n",
    "for k in range(2550,3034):\n",
    "    try:\n",
    "        frame = init_video[k]\n",
    "        stretarr = full_logo_recognition(frame, st)\n",
    "        swretarr = full_logo_recognition(frame, sw)\n",
    "        if stretarr[0]:\n",
    "            init_video[k] = draw_frames(frame,stretarr[1][0],stretarr[1][1],stretarr[1][2], [480,130], 0.3, (0, 255, 0))\n",
    "        if swretarr[0]:\n",
    "            init_video[k] = draw_frames(frame,swretarr[1][0],swretarr[1][1],swretarr[1][2], [480,130], 0.3, ( 255,0, 0))\n",
    "    except:\n",
    "        print (k)\n",
    "for k in range(3036,6300):\n",
    "    try:\n",
    "        frame = init_video[k]\n",
    "        stretarr = full_logo_recognition(frame, st)\n",
    "        swretarr = full_logo_recognition(frame, sw)\n",
    "        if stretarr[0]:\n",
    "            init_video[k] = draw_frames(frame,stretarr[1][0],stretarr[1][1],stretarr[1][2], [480,130], 0.3, (0, 255, 0))\n",
    "        if swretarr[0]:\n",
    "            init_video[k] = draw_frames(frame,swretarr[1][0],swretarr[1][1],swretarr[1][2], [480,130], 0.3, ( 255,0, 0))\n",
    "    except:\n",
    "        print (k)\n",
    "for k in range(6300,6930):\n",
    "    try:\n",
    "        frame = init_video[k]\n",
    "        swretarr = full_logo_recognition(frame, sw)\n",
    "        if swretarr[0]:\n",
    "            init_video[k] = draw_frames(frame,swretarr[1][0],swretarr[1][1],swretarr[1][2], [480,130], 0.3, ( 255,0, 0))\n",
    "    except:\n",
    "        print (k)\n",
    "for k in range(6930,len(init_video) - 1):\n",
    "    try:\n",
    "        frame = init_video[k]\n",
    "        stretarr = full_logo_recognition(frame, st)\n",
    "        swretarr = full_logo_recognition(frame, sw)\n",
    "        if stretarr[0]:\n",
    "            init_video[k] = draw_frames(frame,stretarr[1][0],stretarr[1][1],stretarr[1][2], [480,130], 0.3, (0, 255, 0))\n",
    "        if swretarr[0]:\n",
    "            init_video[k] = draw_frames(frame,swretarr[1][0],swretarr[1][1],swretarr[1][2], [480,130], 0.3, ( 255,0, 0))\n",
    "    except:\n",
    "        print (k)\n",
    "with open('output.rgb', \"wb\") as f:\n",
    "    for p in init_video:\n",
    "        output_frame = np.ravel(np.split(p, 3, axis = 2), order = 'C')\n",
    "        f.write (bytes(output_frame))\n",
    "f.close()\n",
    "#output avi for debugging\n",
    "out = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 30, (480, 270))\n",
    "for i in range(len(init_video)):\n",
    "    out.write(init_video[i])\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = cv2.imread('Dataset/Brand Images/{company}_logo.bmp'.format(company = \"starbucks\"))\n",
    "scale_percent = 30 # percent of original size\n",
    "width = int(scale.shape[1] * scale_percent / 100)\n",
    "height = int(scale.shape[0] * scale_percent / 100)\n",
    "dim = (width, height)\n",
    "resized = cv2.resize(scale, dim, interpolation = cv2.INTER_AREA)\n",
    "testlogo = resized\n",
    "for k in range(2300,2500):\n",
    "    testframe = init_video[k]\n",
    "    retarr = full_logo_recognition(testframe, testlogo)\n",
    "    if retarr[0]:\n",
    "        init_video[k] = draw_frames(testframe,retarr[1][0],retarr[1][1],retarr[1][2], [130,130], 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlogo = cv2.imread('Dataset/Brand Images/{company}_logo.bmp'.format(company = \"subway\"))\n",
    "for k in range(6750,6950):\n",
    "    testframe = init_video[k]\n",
    "    retarr = full_logo_recognition(testframe, testlogo)\n",
    "    if retarr[0]:\n",
    "        init_video[k] = draw_frames(testframe,retarr[1][0],retarr[1][1],retarr[1][2], [480,130], 0.3)\n",
    "    else:\n",
    "        print(len(retarr[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = Image.fromarray(init_video[2367]).convert('RGB')\n",
    "        #print(data)\n",
    "        #convert rgb frame to png for writing\n",
    "data.save('images/box-test.png'.format(1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output avi for debugging\n",
    "out = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 30, (480, 270))\n",
    "for i in range(1):\n",
    "    out.write(init_video[2367])\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating transform matrix to draw binding box\n",
    "#     good_points = matches[:10]\n",
    "    \n",
    "    \n",
    "#     src_pts = np.float32([ logopoints[m.queryIdx].pt for m in good_points]).reshape(-1,1,2)\n",
    "#     dst_pts = np.float32([ framepoints[m.trainIdx].pt for m in good_points]).reshape(-1,1,2)\n",
    "#     M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "#     matchesMask = mask.ravel().tolist()\n",
    "#     h,w = logo.shape[:2]\n",
    "#     pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "\n",
    "#     dst = cv2.perspectiveTransform(pts,M)\n",
    "#     dst += (w, 0)  # adding offset\n",
    "\n",
    "#     draw_params = dict(matchColor = (0,255,0), # draw matches in green color\n",
    "#                singlePointColor = None,\n",
    "#                matchesMask = matchesMask, # draw only inliers\n",
    "#                flags = 2)\n",
    "\n",
    "#     img3 = cv2.drawMatches(logo,logopoints,frame1,framepoints,good_points, None,**draw_params)\n",
    "\n",
    "# # Draw bounding box in Red\n",
    "#     img3 = cv2.polylines(img3, [np.int32(dst)], True, (0,0,255),3, cv2.LINE_AA)\n",
    "\n",
    "#     cv2.imshow(\"result\", img3)\n",
    "#cv2.waitKey()\n",
    "# or another option for display output\n",
    "#plt.imshow(img3, 'result'), plt.show("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "logo_names = [\"subway\", \"starbucks\"]\n",
    "logos = []\n",
    "for l in logo_names:\n",
    "    if(l==\"starbucks\"):\n",
    "        scale = cv2.imread('Dataset/Brand Images/{company}_logo.bmp'.format(company = l))\n",
    "        scale_percent = 30 # percent of original size\n",
    "        width = int(scale.shape[1] * scale_percent / 100)\n",
    "        height = int(scale.shape[0] * scale_percent / 100)\n",
    "        dim = (width, height)\n",
    "        resized = cv2.resize(scale, dim, interpolation = cv2.INTER_AREA)\n",
    "        logos.append(resized)\n",
    "    else:    \n",
    "        logos.append(plt.imread('Dataset/Brand Images/{company}_logo.bmp'.format(company = l)))\n",
    "#for all the beginning cut sections\n",
    "for k in range(len(cuts_begin)):\n",
    "    loopstart = 0\n",
    "    if not k == 0:\n",
    "        loopstart = cuts_end[k-1]\n",
    "    \n",
    "    #for all the frames before the cut\n",
    "    for j in range(loopstart,cuts_begin[k],30):\n",
    "        \n",
    "        #format each image\n",
    "        img = np.flip(final_video[j],axis = 2)\n",
    "        \n",
    "        tobreak = False\n",
    "        for logo in range(len(logos)):\n",
    "            retarr = full_logo_recognition(img, logos[logo])\n",
    "            #if(retarr[0]):\n",
    "            final_video[j] = draw_frames(testframe,retarr[1][0],retarr[1][1],retarr[1][2], [480,130], 0.3)\n",
    "                \n",
    "                #replaced_advertisements.append(logo_names[logo])\n",
    "                #print(logo_names[logo])\n",
    "                #tobreak = True\n",
    "                #break\n",
    "        #if tobreak:\n",
    "           # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"cuts_begin.txt\", \"w\")\n",
    "f.write(\"cuts_begin.txt\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saves data for java to cut audio\n",
    "ad_times = open(\"ad_times.txt\", \"w\")\n",
    "for i in range(len(replaced_advertisements)):\n",
    "    ad_times.write(replaced_advertisements[i] + \" \" + str(cuts_begin[i]) + \"\\n\")\n",
    "ad_times.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#add function to find points and draw the box for each frame in the video\n",
    "#output video to rgb\n",
    "#\n",
    "with open('final_output.rgb', \"wb\") as f:\n",
    "    for p in final_video:\n",
    "        output_frame = np.ravel(np.split(p, 3, axis = 2), order = 'C')\n",
    "        f.write (bytes(output_frame))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output avi for debugging\n",
    "out = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 30, (480, 270))\n",
    "for i in range(len(final_video)):\n",
    "    out.write(final_video[i])\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output avi for debugging\n",
    "out = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 30, (480, 270))\n",
    "for i in range(len(init_video)):\n",
    "    out.write(init_video[i])\n",
    "out.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

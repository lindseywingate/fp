{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage.metrics import structural_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reads in video to init_video\n",
    "with open(\"dataset/Videos/data_test1.rgb\", \"rb\") as f:\n",
    "    v = np.fromfile(f, np.dtype('B'))\n",
    "#setting the number of pixels in frame\n",
    "pxct = 129600\n",
    "#setting the number of frames\n",
    "frct = (int)(v.size/(3*pxct))\n",
    "init_video = []\n",
    "for frame_number in range(frct):\n",
    "        start = (frame_number) * pxct * 3\n",
    "        curr_frame = v[start:start + 3 * pxct]\n",
    "        final_frame = np.reshape(curr_frame, (480,270,3), order = 'F')\n",
    "        final_frame = np.rot90(final_frame,3)\n",
    "        final_frame = np.flip(final_frame,1)\n",
    "        \n",
    "        #searching these final frames for logos (new cell)\n",
    "        init_video.append(final_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate cuts for advertisement\n",
    "advert_frames = []\n",
    "for frame_number in range(frct - 1):\n",
    "    #calculate new shots with histogram\n",
    "    #less means more similar\n",
    "    hist1 = cv2.calcHist([init_video[frame_number]],[0],None,[256],[0,256])\n",
    "    hist2 = cv2.calcHist([init_video[frame_number + 1]],[0],None,[256],[0,256])\n",
    "    score=cv2.compareHist(hist1,hist2,cv2.HISTCMP_BHATTACHARYYA)\n",
    "    #store score for ssi\n",
    "    #less means more similar\n",
    "    #i1 = cv2.cvtColor(init_video[frame_number], cv2.COLOR_BGR2GRAY)\n",
    "    #i2 = cv2.cvtColor(init_video[frame_number + 1], cv2.COLOR_BGR2GRAY)\n",
    "    #score2 = structural_similarity(i1, i2)\n",
    "    #score2 = 1-score2 \n",
    "    #frame_stats[frame_number][1] = score2\n",
    "    \n",
    "    #score indicates sensitivity for shot changes\n",
    "    if score > 0.3:\n",
    "        advert_frames.append(frame_number)\n",
    "        advert_frames.append(frame_number+1)\n",
    "        #saves the image, currently used for debugging\n",
    "        #if score + score2 > 0.3:\n",
    "        data = Image.fromarray(init_video[frame_number]).convert('RGB')\n",
    "        data.save('images_cut/{}.png'.format(frame_number))\n",
    "        data = Image.fromarray(init_video[frame_number+1]).convert('RGB')\n",
    "        data.save('images_cut/{}.png'.format(frame_number+1))\n",
    "#save beginning and end of cuts in number of frames\n",
    "#storing the advertisements to replace with\n",
    "#indexed the same way as that of cuts_begin and cuts_end\n",
    "#if not to be replaced, a blank line\n",
    "replaced_advertisements = []\n",
    "cuts_begin = []\n",
    "cuts_end = []\n",
    "for i in range(len(advert_frames)):\n",
    "    for j in range(i,len(advert_frames)):\n",
    "        if advert_frames[j] - advert_frames[i] == 449:\n",
    "            cuts_begin.append(advert_frames[i])\n",
    "            cuts_end.append(advert_frames[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image negatives for training\n",
    "# for f in range(frct - 1):\n",
    "#     if f > 3000 or f < 1200:\n",
    "#         data = Image.fromarray(init_video[f]).convert('RGB')\n",
    "#         data.save('negative_images/{}.png'.format(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[605, 606, 1178, 1179, 2399, 2400, 2434, 2435, 2488, 2489, 2514, 2515, 2595, 2596, 2658, 2659, 2694, 2695, 2849, 2850, 3629, 3630, 5549, 5550, 5698, 5699, 5845, 5846, 5999, 6000]\n",
      "[2400, 5550]\n"
     ]
    }
   ],
   "source": [
    "#cuts_begin has all starts of clips of 15seconds (449 frames) long exactly\n",
    "#cuts_end has all the ends\n",
    "print(advert_frames)\n",
    "cuts_begin = []\n",
    "cuts_end = []\n",
    "for i in range(len(advert_frames)):\n",
    "    for j in range(i,len(advert_frames)):\n",
    "        if advert_frames[j] - advert_frames[i] == 449:\n",
    "            cuts_begin.append(advert_frames[i])\n",
    "            cuts_end.append(advert_frames[j])\n",
    "print(cuts_begin)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in all other advertisements\n",
    "#saves in a dictionary with first part assumed to be the company name\n",
    "\n",
    "advertisements = {}\n",
    "PATHS_TO_ADVERTISEMENTS = \"dataset/Ads\"\n",
    "for file in os.listdir(PATHS_TO_ADVERTISEMENTS):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.endswith(\".rgb\"): \n",
    "        vpath = os.path.join(PATHS_TO_ADVERTISEMENTS, filename)\n",
    "        with open(vpath, \"rb\") as f:\n",
    "            v = np.fromfile(f, np.dtype('B'))\n",
    "        #setting the number of pixels in frame\n",
    "        pxct = 129600\n",
    "        #setting the number of frames\n",
    "        frct = (int)(v.size/(3*pxct))\n",
    "        video = []\n",
    "        for frame_number in range(frct):\n",
    "            start = (frame_number) * pxct * 3\n",
    "            curr_frame = v[start:start + 3 * pxct]\n",
    "            final_frame = np.reshape(curr_frame, ( 480,270, 3), order = 'F')\n",
    "            final_frame = np.rot90(final_frame,3)\n",
    "            final_frame = np.flip(final_frame,1)\n",
    "            video.append(final_frame)\n",
    "        #Get the name of the company\n",
    "        key = filename.split('_')[0]\n",
    "        advertisements[key] = video\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splicing in videos with the names \n",
    "#save beginning and end of cuts in number of frames\n",
    "\n",
    "#storing the advertisements to replace with\n",
    "#indexed the same way as that of cuts_begin and cuts_end\n",
    "#if not to be replaced, an empty string\n",
    "replaced_advertisements = [\"Subway\", \"Starbucks\"]\n",
    "final_video = []\n",
    "for i in range (len(cuts_begin)):\n",
    "    if i == 0:\n",
    "        final_video = init_video[:cuts_begin[i]] + advertisements[replaced_advertisements[i]] + init_video[cuts_end[i]:]\n",
    "    else:\n",
    "        #further work required to sync frames iff replacement ad lengths are variable\n",
    "        final_video = final_video[:cuts_begin[i]] + advertisements[replaced_advertisements[i]] + final_video[cuts_end[i]:]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experimenting with SIFT\n",
    "#finding points and comparing across image \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#returns boolean if logo of logo_path is recognized in frame\n",
    "def logo_recognition(frame, logo):\n",
    "    #read in logo \n",
    "    graylogo = cv2.cvtColor(logo, cv2.COLOR_BGR2GRAY)\n",
    "#cv2.imshow('image', graylogo)\n",
    "#cv2.waitKey(5000)\n",
    "\n",
    "# #read in frame from video\n",
    "    #frame = Image.fromarray(final_video[2100]).convert('RGB')\n",
    "\n",
    "# #reformat\n",
    "    #frame.save('images/box-test.png'.format(1));\n",
    "    #frame1 = cv2.imread('images/box-test.png')\n",
    "\n",
    "# #change to grayscale\n",
    "    grayframe = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    logopoints, logodescriptors = sift.detectAndCompute(graylogo, None)\n",
    "    framepoints, framedescriptors = sift.detectAndCompute(grayframe, None)\n",
    "\n",
    "    #bf = cv2.BFMatcher(cv2.NORM_L1, crossCheck=True)\n",
    "    bf = cv2.BFMatcher()\n",
    "\n",
    "    #matches = bf.match(logodescriptors,framedescriptors)\n",
    "    matches = bf.knnMatch(logodescriptors,framedescriptors, k=2)\n",
    "\n",
    "#matches = sorted(matches, key = lambda x:x.distance)\n",
    "\n",
    "    # Apply ratio test\n",
    "    good_points = []\n",
    "    for m,n in matches:\n",
    "       if m.distance < 0.69*n.distance:\n",
    "           good_points.append([m])\n",
    "    #print(good_points)\n",
    "\n",
    "# cv2.drawMatchesKnn expects list of lists as matches.\n",
    "    img3 = cv2.drawMatchesKnn(logo, logopoints, frame, framepoints, good_points, None,\n",
    "                              matchColor=(0, 255, 0), matchesMask=None,\n",
    "                              singlePointColor=(255, 0, 0), flags=0)\n",
    "\n",
    "    #plt.imshow(img3),plt.show()\n",
    "    return (len(good_points) > 7)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating transform matrix to draw binding box\n",
    "#     good_points = matches[:10]\n",
    "    \n",
    "    \n",
    "#     src_pts = np.float32([ logopoints[m.queryIdx].pt for m in good_points]).reshape(-1,1,2)\n",
    "#     dst_pts = np.float32([ framepoints[m.trainIdx].pt for m in good_points]).reshape(-1,1,2)\n",
    "#     M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "#     matchesMask = mask.ravel().tolist()\n",
    "#     h,w = logo.shape[:2]\n",
    "#     pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "\n",
    "#     dst = cv2.perspectiveTransform(pts,M)\n",
    "#     dst += (w, 0)  # adding offset\n",
    "\n",
    "#     draw_params = dict(matchColor = (0,255,0), # draw matches in green color\n",
    "#                singlePointColor = None,\n",
    "#                matchesMask = matchesMask, # draw only inliers\n",
    "#                flags = 2)\n",
    "\n",
    "#     img3 = cv2.drawMatches(logo,logopoints,frame1,framepoints,good_points, None,**draw_params)\n",
    "\n",
    "# # Draw bounding box in Red\n",
    "#     img3 = cv2.polylines(img3, [np.int32(dst)], True, (0,0,255),3, cv2.LINE_AA)\n",
    "\n",
    "#     cv2.imshow(\"result\", img3)\n",
    "#cv2.waitKey()\n",
    "# or another option for display output\n",
    "#plt.imshow(img3, 'result'), plt.show("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) :-1: error: (-5:Bad argument) in function 'cvtColor'\n> Overload resolution failed:\n>  - src is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'src'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Input \u001b[1;32mIn [76]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m logo_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubway\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstarbucks\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m logo \u001b[38;5;129;01min\u001b[39;00m logo_names:\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(\u001b[43mlogo_recognition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlogo\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[0;32m     20\u001b[0m         replaced_advertisements\u001b[38;5;241m.\u001b[39mappend(logo)\n",
      "Input \u001b[1;32mIn [75]\u001b[0m, in \u001b[0;36mlogo_recognition\u001b[1;34m(frame, logo)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlogo_recognition\u001b[39m(frame, logo):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m#read in logo \u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     graylogo \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2GRAY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#cv2.imshow('image', graylogo)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#cv2.waitKey(5000)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m \n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# #change to grayscale\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     grayframe \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.5) :-1: error: (-5:Bad argument) in function 'cvtColor'\n> Overload resolution failed:\n>  - src is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'src'\n"
     ]
    }
   ],
   "source": [
    "#create the video\n",
    "#file path, format, frames per second, width and height\n",
    "out = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 30, (480, 270))\n",
    "#RGBA format\n",
    "#frames = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60]    \n",
    "#store all logos recognized in replaced_advertisements[]\n",
    "for i in range(len(final_video)):\n",
    "    #cv2.imshow('images/box-1.png', img)\n",
    "    data = Image.fromarray(final_video[i]).convert('RGB')\n",
    "    #print(data)\n",
    "    #convert rgb frame to png for writing\n",
    "    data.save('images/box-test.png'.format(1));\n",
    "    #get new saved png frame\n",
    "    img = cv2.imread('images/box-test.png')\n",
    "    #call the sift algorithm\n",
    "    #if there are matches, we return the frames that they exist in\n",
    "    logo_names = [\"subway\", \"starbucks\"]\n",
    "    for logo in logo_names:\n",
    "        if(logo_recognition(img,logo)):\n",
    "            replaced_advertisements.append(logo)\n",
    "\n",
    "    #write on image here\n",
    "#    if(i in frames):\n",
    "# #draw rectangle on frame\n",
    "#         cv2.rectangle(img, (10,10), (100, 100), (0, 255, 0), 2)\n",
    "# #just to verify box comes out in right spot\n",
    "#         cv2.imwrite(\"images/test-box.png\", img)\n",
    "\n",
    "#     #change back to rgb for avi video\n",
    "#         #img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#         out.write(img)\n",
    "#     else:\n",
    "    #out.write(img)\n",
    "\n",
    "#out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starbucks\n",
      "subway\n"
     ]
    }
   ],
   "source": [
    "logo_names = [\"subway\", \"starbucks\"]\n",
    "logos = []\n",
    "replaced_advertisements = []\n",
    "for l in logo_names:\n",
    "    logos.append(plt.imread('Dataset/Brand Images/{company}_logo.bmp'.format(company = l)))\n",
    "for k in range(len(cuts_begin)):\n",
    "    loopstart = 0\n",
    "    if not k == 0:\n",
    "        loopstart = cuts_end[k-1]\n",
    "    for j in range(loopstart,cuts_begin[k],10):\n",
    "        img = np.flip(final_video[j],axis = 2)\n",
    "        #cv2.imshow('images/box-1.png', img)\n",
    "        #data = Image.fromarray(final_video[i]).convert('RGB')\n",
    "        #print(data)\n",
    "        #convert rgb frame to png for writing\n",
    "        #data.save('images/box-test.png'.format(1));\n",
    "        #get new saved png frame\n",
    "        #img = cv2.imread('images/box-test.png')\n",
    "        #call the sift algorithm\n",
    "        #if there are matches, we return the frames that they exist in\n",
    "        tobreak = False\n",
    "        for logo in range(len(logos)):\n",
    "            if(logo_recognition(img,logos[logo])):\n",
    "                replaced_advertisements.append(logo_names[logo])\n",
    "                print(logo_names[logo])\n",
    "                tobreak = True\n",
    "                break\n",
    "        if tobreak:\n",
    "            break\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"cuts_begin.txt\", \"w\")\n",
    "f.write(cuts_begin)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saves data for java to cut audio\n",
    "ad_times = open(\"ad_times.txt\", \"w\")\n",
    "for i in range(len(replaced_advertisements)):\n",
    "    ad_times.write(replaced_advertisements[i] + \" \" + str(cuts_begin[i]) + \"\\n\")\n",
    "ad_times.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add function to find points and draw the box for each frame in the video\n",
    "#output video to rgb\n",
    "#\n",
    "with open('output.rgb', \"wb\") as f:\n",
    "    for p in final_video:\n",
    "        output_frame = np.ravel(np.split(p, 3, axis = 2), order = 'C')\n",
    "        f.write (bytes(output_frame))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logo_cascade = cv2.CascadeClassifier('data/cascade.xml')\n",
    "img = cv2.imread('class/2040.png')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "logos = logo_cascade.detectMultiScale(gray,1.3, 5)\n",
    "for (x,y,w,h) in logos:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    cv2.imshow('img',img)\n",
    "#data.save('images/{}.png'.format(1337))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output avi for debugging\n",
    "out = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 30, (480, 270))\n",
    "for i in range(len(final_video)):\n",
    "    out.write(final_video[i])\n",
    "out.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21798a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage.metrics import structural_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d690b47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reads in video to init_video\n",
    "with open(\"dataset/Videos/data_test1.rgb\", \"rb\") as f:\n",
    "    v = np.fromfile(f, np.dtype('B'))\n",
    "#setting the number of pixels in frame\n",
    "pxct = 129600\n",
    "#setting the number of frames\n",
    "frct = (int)(v.size/(3*pxct))\n",
    "init_video = []\n",
    "for frame_number in range(frct):\n",
    "        start = (frame_number) * pxct * 3\n",
    "        curr_frame = v[start:start + 3 * pxct]\n",
    "        final_frame = np.reshape(curr_frame, (480,270,3), order = 'F')\n",
    "        final_frame = np.rot90(final_frame,3)\n",
    "        final_frame = np.flip(final_frame,1)\n",
    "        \n",
    "        #searching these final frames for logos (new cell)\n",
    "        init_video.append(final_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cdf0daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate cuts for advertisement\n",
    "advert_frames = []\n",
    "for frame_number in range(frct - 1):\n",
    "    #calculate new shots with histogram\n",
    "    #less means more similar\n",
    "    hist1 = cv2.calcHist([init_video[frame_number]],[0],None,[256],[0,256])\n",
    "    hist2 = cv2.calcHist([init_video[frame_number + 1]],[0],None,[256],[0,256])\n",
    "    score=cv2.compareHist(hist1,hist2,cv2.HISTCMP_BHATTACHARYYA)\n",
    "    #store score for ssi\n",
    "    #less means more similar\n",
    "    #i1 = cv2.cvtColor(init_video[frame_number], cv2.COLOR_BGR2GRAY)\n",
    "    #i2 = cv2.cvtColor(init_video[frame_number + 1], cv2.COLOR_BGR2GRAY)\n",
    "    #score2 = structural_similarity(i1, i2)\n",
    "    #score2 = 1-score2 \n",
    "    #frame_stats[frame_number][1] = score2\n",
    "    \n",
    "    #score indicates sensitivity for shot changes\n",
    "    if score > 0.3:\n",
    "        advert_frames.append(frame_number)\n",
    "        advert_frames.append(frame_number+1)\n",
    "        #saves the image, currently used for debugging\n",
    "        #if score + score2 > 0.3:\n",
    "        data = Image.fromarray(init_video[frame_number]).convert('RGB')\n",
    "        data.save('images_cut/{}.png'.format(frame_number))\n",
    "        data = Image.fromarray(init_video[frame_number+1]).convert('RGB')\n",
    "        data.save('images_cut/{}.png'.format(frame_number+1))\n",
    "#save beginning and end of cuts in number of frames\n",
    "#storing the advertisements to replace with\n",
    "#indexed the same way as that of cuts_begin and cuts_end\n",
    "#if not to be replaced, a blank line\n",
    "replaced_advertisements = []\n",
    "cuts_begin = []\n",
    "cuts_end = []\n",
    "for i in range(len(advert_frames)):\n",
    "    for j in range(i,len(advert_frames)):\n",
    "        if advert_frames[j] - advert_frames[i] == 449:\n",
    "            cuts_begin.append(advert_frames[i])\n",
    "            cuts_end.append(advert_frames[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2dea319",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image negatives for training\n",
    "# for f in range(frct - 1):\n",
    "#     if f > 3000 or f < 1200:\n",
    "#         data = Image.fromarray(init_video[f]).convert('RGB')\n",
    "#         data.save('negative_images/{}.png'.format(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ba0db14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Starbucks', 'Subway'])\n"
     ]
    }
   ],
   "source": [
    "#reading in all other advertisements\n",
    "#saves in a dictionary with first part assumed to be the company name\n",
    "advertisements = {}\n",
    "PATHS_TO_ADVERTISEMENTS = \"dataset/Ads\"\n",
    "for file in os.listdir(PATHS_TO_ADVERTISEMENTS):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.endswith(\".rgb\"): \n",
    "        vpath = os.path.join(PATHS_TO_ADVERTISEMENTS, filename)\n",
    "        with open(vpath, \"rb\") as f:\n",
    "            v = np.fromfile(f, np.dtype('B'))\n",
    "        #setting the number of pixels in frame\n",
    "        pxct = 129600\n",
    "        #setting the number of frames\n",
    "        frct = (int)(v.size/(3*pxct))\n",
    "        video = []\n",
    "        for frame_number in range(frct):\n",
    "            start = (frame_number) * pxct * 3\n",
    "            curr_frame = v[start:start + 3 * pxct]\n",
    "            final_frame = np.reshape(curr_frame, ( 480,270, 3), order = 'F')\n",
    "            final_frame = np.rot90(final_frame,3)\n",
    "            final_frame = np.flip(final_frame,1)\n",
    "            video.append(final_frame)\n",
    "        #Get the name of the company\n",
    "        key = filename.split('_')[0]\n",
    "        advertisements[key] = video\n",
    "        \n",
    "print(advertisements.keys())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "992c1f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splicing in videos with the names \n",
    "#save beginning and end of cuts in number of frames\n",
    "cuts_begin = [2400]\n",
    "cuts_end = [2849]\n",
    "#storing the advertisements to replace with\n",
    "#indexed the same way as that of cuts_begin and cuts_end\n",
    "#if not to be replaced, an empty string\n",
    "replaced_advertisements = [\"Subway\"]\n",
    "final_video = []\n",
    "for i in range (len(cuts_begin)):\n",
    "    if i == 0:\n",
    "        final_video = init_video[:cuts_begin[i]] + advertisements[replaced_advertisements[i]] + init_video[cuts_end[i]:]\n",
    "    else:\n",
    "        #further work required to sync frames iff ad lengths are variable\n",
    "        final_video = final_video[:cuts_begin[i]] + advertisements[replaced_advertisements[i]] + final_video[cuts_end[i]:]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "561f74a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#experimenting with SIFT\n",
    "#finding points and comparing across image \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#returns boolean if logo of logo_path is recognized in frame\n",
    "def logo_recognition(frame, logo):\n",
    "    #read in logo \n",
    "    graylogo = cv2.cvtColor(logo, cv2.COLOR_BGR2GRAY)\n",
    "#cv2.imshow('image', graylogo)\n",
    "#cv2.waitKey(5000)\n",
    "\n",
    "# #read in frame from video\n",
    "    #frame = Image.fromarray(final_video[2100]).convert('RGB')\n",
    "\n",
    "# #reformat\n",
    "    #frame.save('images/box-test.png'.format(1));\n",
    "    #frame1 = cv2.imread('images/box-test.png')\n",
    "\n",
    "# #change to grayscale\n",
    "    grayframe = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    logopoints, logodescriptors = sift.detectAndCompute(graylogo, None)\n",
    "    framepoints, framedescriptors = sift.detectAndCompute(grayframe, None)\n",
    "\n",
    "    #bf = cv2.BFMatcher(cv2.NORM_L1, crossCheck=True)\n",
    "    bf = cv2.BFMatcher()\n",
    "\n",
    "    #matches = bf.match(logodescriptors,framedescriptors)\n",
    "    matches = bf.knnMatch(logodescriptors,framedescriptors, k=2)\n",
    "\n",
    "#matches = sorted(matches, key = lambda x:x.distance)\n",
    "\n",
    "    # Apply ratio test\n",
    "    good_points = []\n",
    "    for m,n in matches:\n",
    "       if m.distance < 0.69*n.distance:\n",
    "           good_points.append([m])\n",
    "    #print(good_points)\n",
    "\n",
    "# cv2.drawMatchesKnn expects list of lists as matches.\n",
    "    img3 = cv2.drawMatchesKnn(logo, logopoints, frame, framepoints, good_points, None,\n",
    "                              matchColor=(0, 255, 0), matchesMask=None,\n",
    "                              singlePointColor=(255, 0, 0), flags=0)\n",
    "\n",
    "    #plt.imshow(img3),plt.show()\n",
    "    return (len(good_points) > 7)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73cf247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating transform matrix to draw binding box\n",
    "#     good_points = matches[:10]\n",
    "    \n",
    "    \n",
    "#     src_pts = np.float32([ logopoints[m.queryIdx].pt for m in good_points]).reshape(-1,1,2)\n",
    "#     dst_pts = np.float32([ framepoints[m.trainIdx].pt for m in good_points]).reshape(-1,1,2)\n",
    "#     M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "#     matchesMask = mask.ravel().tolist()\n",
    "#     h,w = logo.shape[:2]\n",
    "#     pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "\n",
    "#     dst = cv2.perspectiveTransform(pts,M)\n",
    "#     dst += (w, 0)  # adding offset\n",
    "\n",
    "#     draw_params = dict(matchColor = (0,255,0), # draw matches in green color\n",
    "#                singlePointColor = None,\n",
    "#                matchesMask = matchesMask, # draw only inliers\n",
    "#                flags = 2)\n",
    "\n",
    "#     img3 = cv2.drawMatches(logo,logopoints,frame1,framepoints,good_points, None,**draw_params)\n",
    "\n",
    "# # Draw bounding box in Red\n",
    "#     img3 = cv2.polylines(img3, [np.int32(dst)], True, (0,0,255),3, cv2.LINE_AA)\n",
    "\n",
    "#     cv2.imshow(\"result\", img3)\n",
    "#cv2.waitKey()\n",
    "# or another option for display output\n",
    "#plt.imshow(img3, 'result'), plt.show("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "056e54e3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starbucks\n"
     ]
    }
   ],
   "source": [
    "logo_names = [\"subway\", \"starbucks\"]\n",
    "logos = []\n",
    "replaced_advertisements = []\n",
    "for l in logo_names:\n",
    "    logos.append(plt.imread('Dataset/Brand Images/{company}_logo.bmp'.format(company = l)))\n",
    "for k in range(len(cuts_begin)):\n",
    "    loopstart = 0\n",
    "    if not k == 0:\n",
    "        loopstart = cuts_end[k-1]\n",
    "    for j in range(loopstart,cuts_begin[k],10):\n",
    "        img = np.flip(final_video[j],axis = 2)\n",
    "        #cv2.imshow('images/box-1.png', img)\n",
    "        #data = Image.fromarray(final_video[i]).convert('RGB')\n",
    "        #print(data)\n",
    "        #convert rgb frame to png for writing\n",
    "        #data.save('images/box-test.png'.format(1));\n",
    "        #get new saved png frame\n",
    "        #img = cv2.imread('images/box-test.png')\n",
    "        #call the sift algorithm\n",
    "        #if there are matches, we return the frames that they exist in\n",
    "        tobreak = False\n",
    "        for logo in range(len(logos)):\n",
    "            if(logo_recognition(img,logos[logo])):\n",
    "                replaced_advertisements.append(logo_names[logo])\n",
    "                print(logo_names[logo])\n",
    "                tobreak = True\n",
    "                break\n",
    "        if tobreak:\n",
    "            break\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "984317bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saves data for java to cut audio\n",
    "ad_times = open(\"ad_times.txt\", \"w\")\n",
    "for i in range(len(replaced_advertisements)):\n",
    "    ad_times.write(replaced_advertisements[i] + \" \" + str(cuts_begin[i]) + \"\\n\")\n",
    "ad_times.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76bb9f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add function to find points and draw the box for each frame in the video\n",
    "#output video to rgb\n",
    "#\n",
    "with open('output.rgb', \"wb\") as f:\n",
    "    for p in final_video:\n",
    "        output_frame = np.ravel(np.split(p, 3, axis = 2), order = 'C')\n",
    "        f.write (bytes(output_frame))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db5f355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output avi for debugging\n",
    "out = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 30, (480, 270))\n",
    "for i in range(len(final_video)):\n",
    "    out.write(final_video[i])\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d2146a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
